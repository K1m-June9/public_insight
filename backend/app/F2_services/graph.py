import logging
import math
from typing import Union, Dict, Any, List

from app.F3_repositories.graph import GraphRepository
# ğŸ”§ [ìˆ˜ì •] ìš°ë¦¬ í”„ë¡œì íŠ¸ì˜ ìŠ¤í‚¤ë§ˆë“¤ì„ ì„í¬íŠ¸
from app.F6_schemas.graph import (
    ExploreGraphResponse, 
    ExploreGraphData, 
    GraphNode, 
    GraphEdge,
    WordCloudItem,
    WordCloudResponse
)
from app.F6_schemas.base import ErrorResponse, ErrorDetail, ErrorCode, Message

logger = logging.getLogger(__name__)

class GraphService:
    """
    ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì™€ ê´€ë ¨ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤.
    - ë¦¬í¬ì§€í† ë¦¬ë¡œë¶€í„° ë°›ì€ ë°ì´í„°ë¥¼ API ì‘ë‹µ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ê°€ê³µí•˜ê³  ë³€í™˜í•¨.
    """
    def __init__(self, repo: GraphRepository):
        self.repo = repo

    async def get_initial_graph_by_keyword(
        self, keyword: str
    ) -> Union[ExploreGraphResponse, ErrorResponse]:
        """
        í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¸ë“œë§µ ì´ˆê¸° ê·¸ë˜í”„ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  êµ¬ì¡°í™”í•¨.
        """
        try:
            # 1. ë¦¬í¬ì§€í† ë¦¬ë¥¼ í˜¸ì¶œí•˜ì—¬ Neo4jë¡œë¶€í„° ì›ì‹œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
            raw_graph_data = await self.repo.find_initial_nodes_by_keyword(keyword)

            # 2. ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° (ë¦¬í¬ì§€í† ë¦¬ê°€ Noneì„ ë°˜í™˜í•œ ê²½ìš°)
            if not raw_graph_data:
                return ErrorResponse(
                    error=ErrorDetail(
                        code=ErrorCode.NOT_FOUND,
                        message=f"í‚¤ì›Œë“œ '{keyword}'ì™€ ê´€ë ¨ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                )

            # 3. ì›ì‹œ ë°ì´í„°ë¥¼ nodesì™€ edges ë¦¬ìŠ¤íŠ¸ë¡œ 'ì¬ì¡°ë¦½'
            nodes, edges = self._structure_for_frontend(raw_graph_data)

            # 4. ìµœì¢… ì„±ê³µ ì‘ë‹µ ìŠ¤í‚¤ë§ˆì— ë°ì´í„°ë¥¼ ë‹´ì•„ ìƒì„±
            response_data = ExploreGraphData(nodes=nodes, edges=edges)
            
            return ExploreGraphResponse(success=True, data=response_data)

        except Exception as e:
            logger.error(f"Error in GraphService for keyword '{keyword}': {e}", exc_info=True)
            return ErrorResponse(
                error=ErrorDetail(
                    code=ErrorCode.INTERNAL_ERROR,
                    message=Message.INTERNAL_ERROR
                )
            )
            
    def _structure_for_frontend(self, raw_data: dict) -> tuple[list[GraphNode], list[GraphEdge]]:
        """
        (Helper) ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ë°›ì€ ë°ì´í„°ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜í•¨.
        - ë…¸ë“œì˜ ì´ˆê¸° ìœ„ì¹˜(x, y)ì™€ ë¶€ê°€ ì •ë³´(ë©”íƒ€ë°ì´í„°)ë¥¼ ê³„ì‚°í•˜ì—¬ í¬í•¨í•¨.
        - ì´ˆê¸° í™”ë©´ì—ì„œëŠ” ì¤‘ì‹¬ í‚¤ì›Œë“œì™€ 1ì°¨ ì—°ê²°ëœ ë…¸ë“œ/ì—£ì§€ë§Œ ìƒì„±í•¨.
        """
        nodes: List[GraphNode] = []
        edges: List[GraphEdge] = []
        
        # --- 1. ì¤‘ì‹¬ í‚¤ì›Œë“œ ë…¸ë“œ ìƒì„± ---
        keyword_node_data = raw_data.get('keyword')
        if not keyword_node_data:
            return [], []
            
        keyword_id_str = f"keyword_{keyword_node_data['name']}"
        
        keyword_node = GraphNode(
            id=keyword_id_str,
            type='keyword',
            label=keyword_node_data['name'],
            metadata={} # ì¢Œí‘œëŠ” ë‚˜ì¤‘ì— í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê³„ì‚°í•˜ë¯€ë¡œ ë¹„ì›Œë‘ 
        )
        nodes.append(keyword_node)

        # --- 2. ê´€ë ¨ í”¼ë“œ ë° ê¸°ê´€ ë…¸ë“œ ìƒì„± ---
        # í”¼ë“œì™€ ê¸°ê´€ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ì–´ë‘ë©´ ì¡°íšŒê°€ ë¹ ë¦„
        feeds_map = {feed['id']: feed for feed in raw_data.get('feeds', [])}
        orgs_map = {org['id']: org for org in raw_data.get('organizations', [])}

        # í”¼ë“œ ë…¸ë“œ ìƒì„±
        for feed_id, feed_data in feeds_map.items():
            nodes.append(GraphNode(
                id=f"feed_{feed_id}",
                type='feed',
                label=feed_data['title'],
                metadata={
                    # ìš°ë¦¬ê°€ ë…¼ì˜í–ˆë˜ ëª¨ë“  ë¶€ê°€ ì •ë³´ë¥¼ metadataì— ì¶”ê°€
                    'published_date': str(feed_data.get('published_date')),
                    'view_count': feed_data.get('view_count'),
                    'avg_rating': feed_data.get('average_rating'),
                    'bookmark_count': feed_data.get('bookmark_count')
                }
            ))
        
        # ê¸°ê´€ ë…¸ë“œ ìƒì„±
        for org_id, org_data in orgs_map.items():
            nodes.append(GraphNode(
                id=f"organization_{org_id}",
                type='organization',
                label=org_data['name'],
                metadata={}
            ))
            
        # --- 3. 1ë‹¨ê³„ ì—£ì§€(ê´€ê³„) ìƒì„± ---
        # ë…¸íŠ¸ë¶LM ìŠ¤íƒ€ì¼ì„ ìœ„í•´, ì´ˆê¸° í™”ë©´ì—ì„œëŠ” ì¤‘ì‹¬ í‚¤ì›Œë“œì™€ ë‹¤ë¥¸ ë…¸ë“œë“¤ì„ ì‡ëŠ” ì—£ì§€ë§Œ ìƒì„±í•¨.
        for node in nodes:
            # ğŸ”§ [ìˆ˜ì •] ê°ì²´ì˜ ì†ì„±ì— ì ‘ê·¼í•  ë•ŒëŠ” '.'ì„ ì‚¬ìš©
            # ìê¸° ìì‹ ì´ ì•„ë‹ˆê³ , ì¤‘ì‹¬ ë…¸ë“œ(keyword_node)ê°€ ì•„ë‹Œ ë…¸ë“œë“¤ë§Œ ì—°ê²°
            if node.id != keyword_node.id:
                edges.append(GraphEdge(
                    id=f"{keyword_node.id}-INITIAL_LINK-{node.id}",
                    source=keyword_node.id, # ëª¨ë“  ì—£ì§€ëŠ” ì¤‘ì‹¬ í‚¤ì›Œë“œì—ì„œ ì‹œì‘
                    target=node.id,
                ))
                
        return nodes, edges
        
    async def get_expanded_graph_by_node(
        self, node_id: str, node_type: str,
        # ğŸ”§ [ì‹ ê·œ] í”„ë¡ íŠ¸ì—”ë“œë¡œë¶€í„° í˜„ì¬ í™”ë©´ì— ìˆëŠ” ë…¸ë“œ ID ëª©ë¡ì„ ë°›ìŒ
        #    - ë¬¸ìì—´ë¡œ ë°›ì•„ì„œ setìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
        exclude_ids_str: str | None = None
    ) -> Union[ExploreGraphResponse, ErrorResponse]:
        """
        [ML ê¸°ë°˜ìœ¼ë¡œ ë¦¬íŒ©í† ë§ë¨]
        í´ë¦­ëœ ë…¸ë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ í™•ì¥í•˜ê³ , ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ì— ë”°ë¼ ê²°ê³¼ë¥¼ í•„í„°ë§í•¨.
        """
        try:
            entity_id = node_id.split('_', 1)[-1]
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ setìœ¼ë¡œ ë³€í™˜. ì—†ìœ¼ë©´ ë¹ˆ set.
            exclude_ids = set(exclude_ids_str.split(',')) if exclude_ids_str else set()

            raw_expansion_data: Dict[str, Any] | None = None
            rules: Dict[str, int] = {}

            if node_type == 'feed':
                raw_expansion_data = await self.repo.expand_from_feed(int(entity_id), exclude_ids)
                rules = {'feed': 4, 'keyword': 3, 'organization': 1}
            
            elif node_type == 'organization':
                raw_expansion_data = await self.repo.expand_from_organization(int(entity_id), exclude_ids)
                rules = {'feed': 4, 'keyword': 3}
            
            elif node_type == 'keyword':
                raw_expansion_data = await self.repo.expand_from_keyword(str(entity_id), exclude_ids)
                rules = {'feed': 4, 'keyword': 2, 'organization': 1}
            
            else:
                return ErrorResponse(error=ErrorDetail(code=ErrorCode.BAD_REQUEST, message="ì§€ì›í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ íƒ€ì…ì…ë‹ˆë‹¤."))

            # ë¦¬í¬ì§€í† ë¦¬ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
            if not raw_expansion_data:
                return ExploreGraphResponse(success=True, data=ExploreGraphData(nodes=[], edges=[]))
            
            # 1. ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ì— ë”°ë¼ ìµœì¢… ë…¸ë“œ ëª©ë¡ì„ ì„ ë³„
            final_node_infos = self._filter_and_select_nodes(raw_expansion_data, rules, exclude_ids)
            
            # 2. ì„ ë³„ëœ ë…¸ë“œ ì •ë³´ë¡œ í”„ë¡ íŠ¸ì—”ë“œìš© nodesì™€ edgesë¥¼ ìµœì¢… ì¡°ë¦½
            nodes, edges = self._structure_expansion_for_frontend(node_id, final_node_infos)
            
            response_data = ExploreGraphData(nodes=nodes, edges=edges)
            return ExploreGraphResponse(success=True, data=response_data)

        except Exception as e:
            logger.error(f"Error expanding graph for node '{node_id}': {e}", exc_info=True)
            return ErrorResponse(error=ErrorDetail(code=ErrorCode.INTERNAL_ERROR, message=Message.INTERNAL_ERROR))

    def _filter_and_select_nodes(
        self, 
        raw_data: Dict[str, Any], 
        rules: Dict[str, int],
        exclude_ids: set[str]
    ) -> List[Dict[str, Any]]:
        """
        (Helper) ML ì˜ˆì¸¡ ê²°ê³¼ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ì— ë”°ë¼ ìµœì¢… ë…¸ë“œë¥¼ ì„ ë³„í•¨.
        """
        selected_nodes_map: Dict[str, Dict[str, Any]] = {}
        counts = {node_type: 0 for node_type in rules.keys()}
        
        # 1. ì˜ˆì¸¡ëœ ë…¸ë“œë“¤ë¶€í„° ê·œì¹™ì— ë”°ë¼ ì±„ì›Œë„£ê¸°
        for node_id, similarity in raw_data.get("predicted_nodes", []):
            node_type = node_id.split('_')[0]
            
            # ê·œì¹™ì— í•´ë‹¹í•˜ê³ , í• ë‹¹ëŸ‰ì´ ë‚¨ì•˜ìœ¼ë©°, ì´ë¯¸ ì œì™¸ ëª©ë¡ì— ì—†ëŠ” ê²½ìš°
            if node_type in rules and counts[node_type] < rules[node_type] and node_id not in exclude_ids:
                # ìƒì„¸ ì •ë³´ëŠ” ì•„ì§ ì—†ìœ¼ë¯€ë¡œ, IDì™€ íƒ€ì…, ìœ ì‚¬ë„ë§Œ ì €ì¥
                selected_nodes_map[node_id] = {'id': node_id, 'type': node_type, 'similarity': similarity}
                counts[node_type] += 1

        # 2. Cypherë¡œ í™•ì •ì ìœ¼ë¡œ ê°€ì ¸ì˜¨ ë…¸ë“œ(ê¸°ê´€ ë“±) ì¶”ê°€
        explicit_nodes = raw_data.get("explicit_nodes", {})
        for node_type, node_or_list in explicit_nodes.items():
            # organization, organizations ì²˜ëŸ¼ ë‹¨ìˆ˜/ë³µìˆ˜í˜•ì— ëª¨ë‘ ëŒ€ì‘
            node_type_singular = node_type.rstrip('s') 
            
            if node_type_singular in rules and counts[node_type_singular] < rules[node_type_singular]:
                # ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦
                nodes_to_process = node_or_list if isinstance(node_or_list, list) else [node_or_list]
                
                for node_data in nodes_to_process:
                    if not node_data: continue # ë°ì´í„°ê°€ nullì¸ ê²½ìš° ê±´ë„ˆëœ€
                    
                    node_id = f"{node_type_singular}_{node_data['id']}"
                    
                    # í• ë‹¹ëŸ‰ì´ ë‚¨ì•˜ê³ , ì œì™¸ ëª©ë¡ì— ì—†ìœ¼ë©°, ì•„ì§ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°
                    if counts[node_type_singular] < rules[node_type_singular] and node_id not in exclude_ids and node_id not in selected_nodes_map:
                        selected_nodes_map[node_id] = {'id': node_id, 'type': node_type_singular, 'data': node_data}
                        counts[node_type_singular] += 1

        return list(selected_nodes_map.values())

    def _structure_expansion_for_frontend(
        self, start_node_id: str, final_node_infos: List[Dict[str, Any]]
    ) -> tuple[List[GraphNode], List[GraphEdge]]:
        """
        (Helper) ìµœì¢… ì„ ë³„ëœ ë…¸ë“œ ì •ë³´ ëª©ë¡ì„ í”„ë¡ íŠ¸ì—”ë“œ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜í•¨.
        """
        nodes = []
        edges = []
        
        for item in final_node_infos:
            node_id = item['id']
            generic_type = item['type']
            
            # ìƒì„¸ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ IDì—ì„œ ë¼ë²¨ì„ ìœ ì¶” (ì˜ˆì¸¡ ê²°ê³¼ì˜ ê²½ìš°)
            node_data = item.get('data')
            label = node_data.get('title', node_data.get('name')) if node_data else node_id.split('_', 1)[-1]
            
            nodes.append(GraphNode(
                id=node_id,
                type=generic_type,
                label=label,
                metadata={} # TODO: í•„ìš”ì‹œ node_dataì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            ))

            edges.append(GraphEdge(
                id=f"{start_node_id}-EXPANDS_TO-{node_id}",
                source=start_node_id,
                target=node_id
            ))

        return nodes, edges
    
    # ìƒˆë¡œ ë§Œë“œëŠ”ê±°ê¸´í•œë° ì •ë§ ëˆˆë¬¼ì´ ë‚œë‹¤.
    async def get_wordcloud_data(
        self, organization_name: str | None, limit: int
    ) -> Union[WordCloudResponse, ErrorResponse]:
        """
        ì›Œë“œí´ë¼ìš°ë“œ ë˜ëŠ” ì¸ê¸° í‚¤ì›Œë“œ ëª©ë¡ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  êµ¬ì¡°í™”í•¨.
        """
        try:
            # 1. ë¦¬í¬ì§€í† ë¦¬ë¥¼ í˜¸ì¶œí•˜ì—¬ Neo4jë¡œë¶€í„° ì›ì‹œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
            keywords_data = await self.repo.get_keywords_by_popularity(organization_name, limit)
            
            # 2. Pydantic ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ê³  êµ¬ì¡°ë¥¼ ë§ì¶¤.
            #    ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°(keywords_dataê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°)ì—ë„ 
            #    Pydanticì´ ì•Œì•„ì„œ ì²˜ë¦¬í•˜ì—¬ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì§„ ì„±ê³µ ì‘ë‹µì„ ë§Œë“¤ì–´ ì¤Œ.
            response_data = [WordCloudItem(**item) for item in keywords_data]
            
            # 3. ìµœì¢… ì„±ê³µ ì‘ë‹µ ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜
            return WordCloudResponse(success=True, data=response_data)

        except Exception as e:
            # ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ë°œìƒí•œ ì˜ˆì™¸ë¥¼ í¬í•¨í•œ ëª¨ë“  ì—ëŸ¬ë¥¼ ì²˜ë¦¬
            logger.error(f"Error in get_wordcloud_data service: {e}", exc_info=True)
            return ErrorResponse(
                error=ErrorDetail(
                    code=ErrorCode.INTERNAL_ERROR,
                    message=Message.INTERNAL_ERROR
                )
            )